---
title: "6_24"
output: html_notebook
---

Generate new splits but with all the samples
- rework file paths 
- rework NUMSPLITS and cpgs in each split (change dimensions)

```{r}
library(readr)
library(readxl)
library(DunedinPACE)
library(data.table)
library(pheatmap)

Hannum_CpGs <- read_excel("CpGsToInvestigate/hannum_cpgs.xlsx")
Hannum_CpGs <- Hannum_CpGs$Marker #71
Levine_CpGs <- read.csv("CpGsToInvestigate/levine_cpgs.csv", stringsAsFactors=FALSE)
Levine_CpGs <- Levine_CpGs[-1, ]
Levine_CpGs <- Levine_CpGs$CpG #513
Horvath_CpGs <- read.csv("CpGsToInvestigate/horvath_cpgs.csv", stringsAsFactors=FALSE)
Horvath_CpGs <- Horvath_CpGs[-(1:3), 1, drop=FALSE]
Horvath_CpGs <- Horvath_CpGs[, 1] #350
McEwen_CpGs <- read.csv("CpGsToInvestigate/mcewen_cpgs.csv")
McEwen_CpGs <- McEwen_CpGs$CPG #94
#Wu
Wu_CpGs <- read_excel("CpGsToInvestigate/aging-11-102399-s003..xlsx")
Wu_CpGs <- Wu_CpGs[-1, ]
Wu_CpGs <- Wu_CpGs$CpGs
Belsky_CpGs <- getRequiredProbes(backgroundList=FALSE)
Belsky_CpGs <- unlist(Belsky_CpGs)

list_of_cpgs <- list(Hannum_CpGs, Horvath_CpGs,
                    Levine_CpGs, McEwen_CpGs, Wu_CpGs, Belsky_CpGs)

cpgs <- unlist(list_of_cpgs)
cpgs <- unique(cpgs) #1247 total sites

#write.csv(cpgs, "6_27_overlap.csv")
```


```{r}
training_datasets <- c("GSE50660", "GSE90124", "GSE40279", "GSE67705", "GSE61256", "GSE73103", "GSE124366")
testing_datasets <- c("GSE114134", "GSE89253", "GSE53740", "GSE85568", "GSE106648", "GSE51057", "GSE124076")
all_datasets <- c(training_datasets, testing_datasets)
combined_path <- "/Users/kchen/OneDrive/Documents/methylation/combined18/"
# Read desired CpG sites from overlappingSites()
initial_cpg_list <- read.csv("6_27_overlap.csv")
initial_cpg_list <- initial_cpg_list$x
# Extract number of sites
NUMCPGSITE <- length(initial_cpg_list)

standardizeDataset <- function(df_name, desired_cpgs) {
  df <- readr::read_csv(paste0(combined_path, df_name, "_df.csv"))
  # Extract ages
  ages <- df[1, ]
  df <- df[-1, ]
  template <- data.table(cpg=desired_cpgs)
  # Reorder and filter by reference CpG sites
  df <- merge(template, df, by.x="cpg", by.y="cpg", all.x=TRUE, sort=FALSE)
  # Reattach ages
  df <- rbind(ages, df)
  
  return(df)
}

makeChunks <- function(datasets, output_folder) {
  temp <- data.frame()
  for (dataset in datasets) {
    df <- standardizeDataset(dataset, initial_cpg_list)
    if (ncol(temp) == 0) {
      temp <- df
    } else {
      temp <- cbind(temp, df)
    }
  }
  write.csv(temp, file = paste0(output_folder, "partition_", 1, ".csv"), row.names = TRUE)
}

# Run code
makeChunks(all_datasets, "/Users/kchen/OneDrive/Documents/methylation/combined_split/")
```

New filter -> all CpGs from Horvath, PhenoAge, Hannum, PedBE, and new paper (in CpGsToInvestigate folder)

```{r}
generateMatrix2 <- function(file_with_pre_filter, average) {
  sites <- read.csv(file_with_pre_filter)
  sites <- sites[, -1]
  sites <- as.character(sites)
  #length: 288962
  NUMCPGSITE2 <- length(sites)
  #initialize output matrixs
  B <- matrix(NA, nrow=NUMCPGSITE2, ncol=101)
  age_range <- 0:100
  rownames(B) <- sites
  column_names <- character(101)
  for (i in age_range) {
    column_names[i+1] <- paste0("age_", i)
  }
  colnames(B) <- column_names

  i=1
  temp <- readr::read_csv(paste0("/Users/kchen/OneDrive/Documents/methylation/combined_split/", "partition_", i, ".csv"))
  # Remove extra first column (automatic indices)
  temp <- temp[, -1]
  #filter for sites from correlation function
  des_rows <- which(temp$cpg...466 %in% sites)
  temp <- temp[c(1, des_rows), ] #keep ages in the first row
  # Extract CpG site list
  identifiers <- temp[-1, ncol(temp)]
  for (j in 0:100) {
    # DEBUG // print(paste0("Split: ", i, " Age: ", j))
    des_cols <- which(temp[1, ]==j)
    # DEBUG // print(paste0("Columns at Age ", j, " : ", length(des_cols)))
    # Check if there are samples at age j
    if (length(des_cols)>0) {
      # Filter for age j
      age_data <- temp[, des_cols, drop = FALSE]
      # Drop age row
      age_data <- age_data[-1, ]
      
      #indice of identifiers corresponds to indice of age_data
      #age_data has samples as column names, no other identifiers
      # DEBUG // print(paste0("Dim of age_data: ", dim(age_data)))
      #this step takes the longest
      setDT(age_data)
      # Vectorized averaging
      if (average) {
        aggregated <- age_data[, .(final = rowMeans(.SD, na.rm = TRUE)), by = .I]
      }
      if (!average) {
        aggregated <- age_data[, .(final = apply(.SD, 1, sd, na.rm = TRUE)), by = .I]
      }        
      # DEBUG // print(paste0("Averaging done"))
      aggregated <- as.data.frame(aggregated)
      rownames(aggregated) <- as.character(identifiers$cpg...3952) #2441 for training, 1512 for testing
      # Reassignment to matrix B
      B[rownames(aggregated), paste0("age_", j)] <- aggregated$final
      # DEBUG //print(paste0("Split: ", i, ", Age: ", j, " updated"))
    }
  }
  return(B)
}

V <- generateMatrix2("6_27_overlap.csv", average=TRUE)
write.csv(V, "6_27_small_matrix.csv", row.names=TRUE)
```

```{r}
B <- readr::read_csv("6_27_small_matrix.csv")
B <- B[, colSums(is.na(B)) != nrow(B)]
cpg_site_names <- B[[1]]
B <- B[, -1, with = FALSE]
B <- as.data.frame(B)
rownames(B) <- cpg_site_names
```


```{r}
library(ComplexHeatmap)
library(circlize)

clocks <- c("Hannum", "Horvath", "Levine", "McEwen", "Wu", "Belsky")
clock_annotations <- data.frame(matrix(ncol = length(clocks), nrow = length(rownames(B))))
names(clock_annotations) <- clocks
rownames(clock_annotations) <- rownames(B)

clock_annotations$Hannum[rownames(B) %in% Hannum_CpGs] <- 1
clock_annotations$Horvath[rownames(B) %in% Horvath_CpGs] <- 1
clock_annotations$Levine[rownames(B) %in% Levine_CpGs] <- 1
clock_annotations$McEwen[rownames(B) %in% McEwen_CpGs] <- 1
clock_annotations$Wu[rownames(B) %in% Wu_CpGs] <- 1
clock_annotations$Belsky[rownames(B) %in% Belsky_CpGs] <- 1

clock_annotations[is.na(clock_annotations)] <- 0

B <- t(scale(t(B)))
B <- as.matrix(B)
colnames(B) <- gsub("age_", "", colnames(B))

ha = rowAnnotation(df = clock_annotations, col = list(
    Hannum = c("0" = "gray", "1" = "red"),
    Horvath = c("0" = "gray", "1" = "blue"),
    Levine = c("0" = "gray", "1" = "green"),
    McEwen = c("0" = "gray", "1" = "purple"),
    Wu = c("0" = "gray", "1" = "orange"),
    Belsky = c("0" = "gray", "1" = "yellow")
))


Heatmap(B, 
        name = "Beta Values", 
        right_annotation = ha, 
        show_row_names = FALSE, 
        show_column_names = TRUE,
        cluster_rows = TRUE,
        cluster_columns = FALSE,
        row_title = "CpG Sites", 
        column_title = "Ages",
        column_names_gp = gpar(fontsize = 4, fontface="plain", fontfamily="serif"),
        column_names_rot = 0
)
```


BELOW IS OLD CODE

Reformat new matrix
- Remove ages 0, 1, 2 because values are very sparse
- use linear interpolation for the rest of them to preserve patterns (removing all NAs reduces the list of CpGs down to 267 out of 1074)
- also, for some sites missing values at ages, 87-96, so filled in with last value (only for clustering)
- Heatmap is plotted without any interpolation
```{r}
"""
library(zoo)
B <- readr::read_csv("6_27_small_matrix.csv")
B <- B[, colSums(is.na(B)) != nrow(B)]
cpg_site_names <- B[[1]]
B <- B[, -1, with = FALSE]
B <- as.data.frame(B)
rownames(B) <- cpg_site_names
B <- B[, -(1:3)]
B_interpolated <- data.frame(t(apply(B, 1, function(x) {
    interpolated <- na.approx(x, na.rm = FALSE) 
    first_non_na <- which(!is.na(interpolated))[1]
    if (!is.na(first_non_na)) {
        interpolated[1:first_non_na] <- interpolated[first_non_na]
    }
    last_non_na <- which(!is.na(interpolated))[length(which(!is.na(interpolated)))]
    if (!is.na(last_non_na)) {
        interpolated[last_non_na:length(interpolated)] <- interpolated[last_non_na]
    }
    return(interpolated)
})))
colnames(B_interpolated) <- colnames(B)
#scale
scaled_B <- t(scale(t(B_interpolated)))
df <- as.data.frame(scaled_B)
"""
```

Hierarchical Clustering

```{r}
"""
d <- dist(df, method = "euclidean")  # Compute the distance matrix
hc <- hclust(d, method = "ward.D2")  # Perform hierarchical clustering

# Plot the dendrogram
plot(hc, main = "Dendrogram", xlab = "Sample index", ylab = "Height")
"""
```
```{r}
"""
clusters <- cutree(hc, k = 4)
df$Cluster <- as.factor(clusters)
df <- df[order(df$Cluster), ]
row_order <- rownames(df)

scaledB <- t(scale(t(B)))
df2 <- as.data.frame(scaledB)
original <- df2[row_order, ]
"""
```

Simple heatmap

```{r}
"""
library(pheatmap)
pheatmap(as.matrix(original),  # Exclude cluster column
         scale = "none",
         show_rownames = FALSE,
         show_colnames = TRUE,
         cluster_cols = FALSE,
         cluster_rows = FALSE,
         color = colorRampPalette(c("blue", "white", "red"))(100),
         fontsize_col = 6,
         angle_col = 45,
         main="Clock CpGs",
         breaks = seq(-5, 5, length.out = 101)
)
"""
```

Read annotations

```{r}
annotation <- read.table(gzfile("HM450.hg38.manifest.tsv.gz"), sep="\t", header=TRUE, quote="", comment.char="", fileEncoding = "UTF-8")
```


Pathway Enrichment Analysis

- examine single dataset
- 



